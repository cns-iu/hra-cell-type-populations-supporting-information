{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A notebook to check millitome datasets against hra-pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\abueckle\\documents\\github\\hra-cell-type-populations-supporting-information\\.venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\abueckle\\documents\\github\\hra-cell-type-populations-supporting-information\\.venv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\abueckle\\documents\\github\\hra-cell-type-populations-supporting-information\\.venv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abueckle\\documents\\github\\hra-cell-type-populations-supporting-information\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abueckle\\documents\\github\\hra-cell-type-populations-supporting-information\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abueckle\\documents\\github\\hra-cell-type-populations-supporting-information\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abueckle\\documents\\github\\hra-cell-type-populations-supporting-information\\.venv\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abueckle\\documents\\github\\hra-cell-type-populations-supporting-information\\.venv\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abueckle\\documents\\github\\hra-cell-type-populations-supporting-information\\.venv\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abueckle\\documents\\github\\hra-cell-type-populations-supporting-information\\.venv\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abueckle\\documents\\github\\hra-cell-type-populations-supporting-information\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install and import libraries\n",
    "%pip install pandas requests\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from io import StringIO\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up authentication, note that you need to provide this yourself!\n",
    "with open('data/token.txt', \"r\") as file_object:\n",
    "  TOKEN = file_object.readline()\n",
    "  \n",
    "headers = {'Authorization': f'Bearer {TOKEN}'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hra-pop Universe data from Sankey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abueckle\\AppData\\Local\\Temp\\1\\ipykernel_10192\\1316524802.py:5: DtypeWarning: Columns (1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sankey = pd.read_csv(sankey_url)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>portal</th>\n",
       "      <th>unique_dataset_id</th>\n",
       "      <th>is_rui_registered</th>\n",
       "      <th>is_atlas_dataset</th>\n",
       "      <th>has_millitome_block</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HuBMAP</td>\n",
       "      <td>http://purl.org/ccf/10.1016/j.cell.2022.12.028...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>HuBMAP</td>\n",
       "      <td>http://purl.org/ccf/UFL0006-SP-1-2-1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>HuBMAP</td>\n",
       "      <td>http://purl.org/ccf/UFL0006-SP-1-3-1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>HuBMAP</td>\n",
       "      <td>http://purl.org/ccf/UFL0007-SP-1-1-1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>HuBMAP</td>\n",
       "      <td>http://purl.org/ccf/UFL0007-SP-2-2-1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15584</th>\n",
       "      <td>HuBMAP</td>\n",
       "      <td>https://entity.api.hubmapconsortium.org/entiti...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15585</th>\n",
       "      <td>HuBMAP</td>\n",
       "      <td>https://entity.api.hubmapconsortium.org/entiti...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15586</th>\n",
       "      <td>HuBMAP</td>\n",
       "      <td>https://entity.api.hubmapconsortium.org/entiti...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15587</th>\n",
       "      <td>HuBMAP</td>\n",
       "      <td>https://entity.api.hubmapconsortium.org/entiti...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588</th>\n",
       "      <td>HuBMAP</td>\n",
       "      <td>https://entity.api.hubmapconsortium.org/entiti...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3142 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       portal                                  unique_dataset_id  \\\n",
       "5      HuBMAP  http://purl.org/ccf/10.1016/j.cell.2022.12.028...   \n",
       "88     HuBMAP               http://purl.org/ccf/UFL0006-SP-1-2-1   \n",
       "89     HuBMAP               http://purl.org/ccf/UFL0006-SP-1-3-1   \n",
       "90     HuBMAP               http://purl.org/ccf/UFL0007-SP-1-1-1   \n",
       "91     HuBMAP               http://purl.org/ccf/UFL0007-SP-2-2-1   \n",
       "...       ...                                                ...   \n",
       "15584  HuBMAP  https://entity.api.hubmapconsortium.org/entiti...   \n",
       "15585  HuBMAP  https://entity.api.hubmapconsortium.org/entiti...   \n",
       "15586  HuBMAP  https://entity.api.hubmapconsortium.org/entiti...   \n",
       "15587  HuBMAP  https://entity.api.hubmapconsortium.org/entiti...   \n",
       "15588  HuBMAP  https://entity.api.hubmapconsortium.org/entiti...   \n",
       "\n",
       "       is_rui_registered  is_atlas_dataset  has_millitome_block  \n",
       "5                   True             False                False  \n",
       "88                  True             False                False  \n",
       "89                  True             False                False  \n",
       "90                  True             False                False  \n",
       "91                  True             False                False  \n",
       "...                  ...               ...                  ...  \n",
       "15584               True             False                False  \n",
       "15585               True              True                False  \n",
       "15586               True             False                False  \n",
       "15587               True             False                False  \n",
       "15588               True             False                False  \n",
       "\n",
       "[3142 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sankey data\n",
    "sankey_url = 'https://raw.githubusercontent.com/x-atlas-consortia/hra-pop/refs/heads/main/output-data/v0.11.1/reports/universe-ad-hoc/sankey.csv'\n",
    "\n",
    "# read Sankey report from hra-pop as CSV file\n",
    "sankey = pd.read_csv(sankey_url)\n",
    "\n",
    "# filter out HuBMAP datasets and their RUI, atlas status, then keep relevant columns\n",
    "sankey_hubmap = sankey[sankey['portal'] == \"HuBMAP\"][['portal', 'unique_dataset_id','is_rui_registered','is_atlas_dataset']]\n",
    "sankey_hubmap['has_millitome_block'] = False\n",
    "sankey_hubmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform unique_dataset_id column and add to set\n",
    "sankey_hubmap['unique_dataset_id_stripped'] = sankey_hubmap['unique_dataset_id'].apply(lambda s: s.split('/')[-1])\n",
    "sankey_hubmap\n",
    "\n",
    "sankey_ids = set(sankey_hubmap['unique_dataset_id_stripped'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get millitome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HuBMAP Sample ID', 'Donor', 'Link', 'Lab ID', 'Parent organ type',\n",
       "       'BLOCK Location', 'Assay Group', 'millitome_ID', 'HubMAP ID',\n",
       "       'Submission ID', 'sample_lab_id', 'TIssue Block HuBMAP IDs',\n",
       "       'RUI Location', 'Id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "csv_files = glob.glob('data/*.csv')\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file and read it into a dataframe\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# identify HuBMAP IDs from all the columns\n",
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get HuBMAP IDs\n",
    "id_lists = []\n",
    "\n",
    "keep = ['HuBMAP Sample ID','HubMAP ID','TIssue Block HuBMAP IDs']\n",
    "\n",
    "for col_name in combined_df.columns:\n",
    "  if col_name in keep:\n",
    "    id_lists.append(combined_df[col_name].dropna().unique().tolist())\n",
    "\n",
    "hubmap_ids_flat = [id for sub_list in id_lists for id in sub_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary of HuBMAP IDs -> UUIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_url = 'https://entity.api.hubmapconsortium.org/entities/'\n",
    "\n",
    "# initialize dict to hold mapping of HuBMAP ID to UUID\n",
    "hubmap_id_uuid_dict = {}\n",
    "\n",
    "for id in hubmap_ids_flat:\n",
    "  response_descendants = requests.get(f'{entity_url}{id}', headers=headers)\n",
    "  descendants = response_descendants.json()\n",
    "  hubmap_id_uuid_dict[id] = descendants['uuid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load organ look-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LF': 'left fallopian tube',\n",
      " 'LO': 'left ovary',\n",
      " 'RF': 'right fallopian tube',\n",
      " 'RO': 'right ovary',\n",
      " 'UT': 'uterus'}\n"
     ]
    }
   ],
   "source": [
    "organ_lookup = {}\n",
    "with open('data/organ-lookup.json') as f:\n",
    "  organ_lookup = json.load(f)\n",
    "pprint(organ_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check against HuBMAP Portal to get descendant dataset IDs + other metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portal URL to get descendants\n",
    "api_base = 'https://entity.api.hubmapconsortium.org'\n",
    "endpoint_entity = f'{api_base}/entities/'\n",
    "endpoint_descendants = f'{api_base}/descendants/'\n",
    "endpoint_ancestors = f'{api_base}/ancestors/'\n",
    "\n",
    "# initialize dict to hold tissue block ID and descendant dataset IDs\n",
    "result = {\n",
    "  'tissue_blocks':[],\n",
    "  'datasets':[],\n",
    "  'is_in_hra_pop_universe':[],\n",
    "  'dataset_type':[],\n",
    "  'organ':[],\n",
    "  'age':[],\n",
    "  'race':[],\n",
    "  'sex':[],\n",
    "  'lead':[],\n",
    "  'email':[]\n",
    "}\n",
    "\n",
    "# loop through millitome tissue block IDs and get descendant datasets\n",
    "for tissue_block, value in list(hubmap_id_uuid_dict.items()):\n",
    "  uuid = hubmap_id_uuid_dict[tissue_block]\n",
    "  \n",
    "  # get associated datasets and metadata: assay types, lead\n",
    "  descendants = requests.get(endpoint_descendants+uuid, headers=headers).json()\n",
    "  \n",
    "  dataset_counter = 0\n",
    "  for descendant in descendants:\n",
    "    if descendant['entity_type'] == \"Dataset\":\n",
    "      result['tissue_blocks'].append(uuid)\n",
    "      result['datasets'].append(descendant['uuid'])\n",
    "      result['is_in_hra_pop_universe'].append(descendant['uuid'] in sankey_ids)\n",
    "      result['dataset_type'].append(descendant['dataset_type'])\n",
    "      dataset_counter = dataset_counter + 1\n",
    "  \n",
    "  # get lead name + email address\n",
    "  entity = requests.get(endpoint_entity+uuid, headers=headers).json()\n",
    "  for _ in range(dataset_counter):\n",
    "    result['lead'].append(entity['created_by_user_displayname'])\n",
    "    result['email'].append(entity['created_by_user_email'])\n",
    "  \n",
    "  # get other metadata for tissue block (organ, donor age/race/sex, millitome (L/R, M/F), tissue section)\n",
    "  ancestors = requests.get(endpoint_ancestors+uuid, headers=headers).json()\n",
    "  for ancestor in ancestors:\n",
    "    if ancestor['entity_type'] == 'Sample':\n",
    "       for _ in range(dataset_counter):\n",
    "        result['organ'].append(organ_lookup[ancestor['organ']]) # use organ look-up to get more verbose string\n",
    "    elif ancestor['entity_type'] == 'Donor':\n",
    "      if 'metadata' in ancestor:\n",
    "        metadata = ancestor['metadata']['organ_donor_data']\n",
    "        labels = [data['data_value'] for data in metadata][:3]\n",
    "        for _ in range(dataset_counter):\n",
    "          result['age'].append(labels[0])\n",
    "          result['race'].append(labels[1])\n",
    "          result['sex'].append(labels[2])\n",
    "      else:\n",
    "        for _ in range(dataset_counter):\n",
    "          result['age'].append(\"\")\n",
    "          result['race'].append(\"\")\n",
    "          result['sex'].append(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "# Export to CSV\n",
    "df.to_csv('output/millitome_datasets_in_hra_pop.csv', index=False)\n",
    "print(\"CSV file has been created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
